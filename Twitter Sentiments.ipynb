{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from os import path, getcwd\n",
    "from itertools import repeat\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "import tweepy \n",
    "from textblob import TextBlob\n",
    "\n",
    "import nltk\n",
    " \n",
    "from wordcloud import WordCloud, ImageColorGenerator, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Twitter for #100DaysOfMlCode into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSUMER_KEY = \"your_key\"\n",
    "CONSUMER_SECERET = 'your_secret'\n",
    "ACCESS_TOKEN = \"your_key\"\n",
    "ACCESS_TOKEN_SECRET = \"your_secret\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_setup():\n",
    "    \"\"\"\n",
    "    Twitter's API setup function.\n",
    "    \"\"\"\n",
    "    # Authentication and access using keys:\n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "\n",
    "    # Return API with authentication:\n",
    "    api = tweepy.API(auth)\n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets extracted: 131.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extractor = twitter_setup()\n",
    "tweets=[]\n",
    "\n",
    "for tweet in tweepy.Cursor(extractor.search,q=\"100DaysOfMLCode\",count=200,\n",
    "                           lang=\"en\").items():tweets.append(tweet.text)\n",
    "\n",
    "print(\"Number of tweets extracted: {}.\\n\".format(len(tweet.text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#100daysOfMLCode D72 Continued training mask R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Fluid65869181 @100DaysOfMLCode If you're inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Grananqvist: #100DaysOfMLCode Day 70 - Sat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#100DaysOfMLCode Day 70 - Sat on a plane for 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets\n",
       "0  #100daysOfMLCode D72 Continued training mask R...\n",
       "1  @Fluid65869181 @100DaysOfMLCode If you're inte...\n",
       "2  RT @Grananqvist: #100DaysOfMLCode Day 70 - Sat...\n",
       "3  #100DaysOfMLCode Day 70 - Sat on a plane for 1..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str1 = ''.join(tweets)\n",
    "data = pd.DataFrame(data=[tweet for tweet in tweets], columns=['Tweets'])\n",
    "data.to_csv('data/100DOMC.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Check Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>SA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#100daysOfMLCode D72 Continued training mask R...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Fluid65869181 @100DaysOfMLCode If you're inte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Grananqvist: #100DaysOfMLCode Day 70 - Sat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#100DaysOfMLCode Day 70 - Sat on a plane for 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  SA\n",
       "0  #100daysOfMLCode D72 Continued training mask R...   0\n",
       "1  @Fluid65869181 @100DaysOfMLCode If you're inte...   1\n",
       "2  RT @Grananqvist: #100DaysOfMLCode Day 70 - Sat...   0\n",
       "3  #100DaysOfMLCode Day 70 - Sat on a plane for 1...   0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_tweet(tweet):\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "def analize_sentiment(tweet):\n",
    "    analysis = TextBlob(clean_tweet(tweet))\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 1\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "    \n",
    "data['SA'] = np.array([ analize_sentiment(tweet) for tweet in data['Tweets'] ])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of positive tweets: 25.0%\n",
      "Percentage of neutral tweets: 75.0%\n",
      "Percentage de negative tweets: 0.0%\n"
     ]
    }
   ],
   "source": [
    "pos_tweets = [ tweet for index, tweet in enumerate(data['Tweets']) if data['SA'][index] > 0]\n",
    "neu_tweets = [ tweet for index, tweet in enumerate(data['Tweets']) if data['SA'][index] == 0]\n",
    "neg_tweets = [ tweet for index, tweet in enumerate(data['Tweets']) if data['SA'][index] < 0]\n",
    "\n",
    "print(\"Percentage of positive tweets: {}%\".format(len(pos_tweets)*100/len(data['Tweets'])))\n",
    "print(\"Percentage of neutral tweets: {}%\".format(len(neu_tweets)*100/len(data['Tweets'])))\n",
    "print(\"Percentage de negative tweets: {}%\".format(len(neg_tweets)*100/len(data['Tweets'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Tweets for WordCloud Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTweet2(str1):\n",
    "    str1 = str1.lower()\n",
    "    str1 = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','',str1)\n",
    "    str1 = re.sub('@[^\\s]+...','',str1)\n",
    "    str1 = re.sub('[\\s]+', ' ', str1)\n",
    "    str1 = re.sub(r'#([^\\s]+)', r'\\1', str1)\n",
    "    str1 = str1.strip('\\'\"')\n",
    "    return str1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "str2= processTweet2(str1)\n",
    "blob= TextBlob(str2)\n",
    "str3=[]\n",
    "count=0\n",
    "for np in blob.noun_phrases:\n",
    "  \n",
    "  str3.append(np)\n",
    "  count+=1\n",
    "str4=''.join(str3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('brown')\n",
    "\n",
    "d = getcwd()\n",
    "\n",
    "text= ''.join(str2)\n",
    "stp=list(set(STOPWORDS))\n",
    "w=['hi','ur','dear','rt','even','really','still','...','now','please','getting','guy','want','day','will','using','make','give']\n",
    "q=w+stp\n",
    "\n",
    "\n",
    "mask = np.array(Image.open(path.join(d, \"\"image/Twitter-Logo.jpg\"\")))\n",
    "wc = WordCloud(background_color=\"white\", max_words=500, mask=mask,stopwords=q,max_font_size=90, random_state=42)\n",
    "wc.generate(text)\n",
    "image_colors = ImageColorGenerator(mask)\n",
    "plt.figure(figsize=[10,10],dpi=400)\n",
    "plt.tight_layout(pad=0)\n",
    "plt.imshow(wc.recolor(color_func=image_colors), interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess and Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.TreebankWordTokenizer()    \n",
    "\n",
    "alfa=0.1\n",
    "zen=3\n",
    "\n",
    "def prob(w,t,es,fs):\n",
    "    if w in es[t]:\n",
    "        return(float(es[t][w]+alfa)/(fs[w]+alfa*zen))\n",
    "    else:\n",
    "        return(float(alfa)/(fs[w]+alfa*zen))\n",
    "    \n",
    "def emisn(w,t,es,fs):\n",
    "    if w in es[t]:\n",
    "        return(float(es[t][w]+alfa)/(fs[t]+alfa*zen))\n",
    "    else:\n",
    "        return(float(alfa)/(fs[t]+alfa*zen))\n",
    "\n",
    "def transn(t1,t2,ts,fs):\n",
    "    if t2 in ts[t1]:\n",
    "        return(float(ts[t1][t2]+alfa)/(fs[t1]+alfa*zen))\n",
    "    else:\n",
    "        return (float(alfa)/(fs[t1]+alfa*zen))\n",
    "    \n",
    "freqs = {}\n",
    "tagfreqs={}\n",
    "tags = defaultdict(dict)\n",
    "trans = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('data/100DOMC.csv','rt') \n",
    "text=f.read()\n",
    "f.close()\n",
    "\n",
    "lines = text.splitlines()\n",
    "for line in lines:\n",
    "    t=0\n",
    "    if len(line.split(\" \"))<=1:\n",
    "        continue\n",
    "    tokens=line.split(\"\\t\")\n",
    "    sen=tokens[0]\n",
    "    tokens=tokens[0].split(\" \")\n",
    "    tokens.insert(0,\"START\")\n",
    "    tokens.append(\"END\")\n",
    "    while t<len(tokens):\n",
    "        try:\n",
    "            freqs[tokens[t]]+=1\n",
    "        except:\n",
    "            freqs[tokens[t]]=1\n",
    "        try:\n",
    "            tagfreqs[sen]+=1\n",
    "        except:\n",
    "            tagfreqs[sen]=1\n",
    "        try:\n",
    "            tagfreqs[\"START\"]+=1\n",
    "        except:\n",
    "            tagfreqs[\"START\"]=1\n",
    "        try:\n",
    "            tags[sen][tokens[t]]+=1\n",
    "        except:\n",
    "            tags[sen][tokens[t]]=1\n",
    "        t+=1\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Completed\n"
     ]
    }
   ],
   "source": [
    "for line in lines:\n",
    "    t=0\n",
    "    if len(line.split(\" \"))<=1:\n",
    "        continue\n",
    "    tokens=line.split(\" \")\n",
    "    sen=tokens[0]\n",
    "    st=[\"START\"]\n",
    "    tokens=tokens[1:]\n",
    "    tokens.insert(0,\"START\")\n",
    "    tokens.append(\"END\")\n",
    "    while t<len(tokens)-1:\n",
    "        if tokens[t]==\"START\":\n",
    "            z=max(tags.keys(), key=lambda tag:prob(tokens[t+1],tag,tags,freqs))\n",
    "            try:\n",
    "                trans[\"START\"][z]+=1\n",
    "            except:\n",
    "                trans[\"START\"][z]=1\n",
    "        else:\n",
    "            z=max(tags.keys(), key=lambda tag:prob(tokens[t+1],tag,tags,freqs))\n",
    "            y=max(tags.keys(), key=lambda tag:prob(tokens[t],tag,tags,freqs))\n",
    "            try:\n",
    "                trans[y][z]+=1\n",
    "            except:\n",
    "                trans[y][z]=1            \n",
    "        t+=1\n",
    "    \n",
    "print(\"Training Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM using Viteri Alg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(fs,es,ts,ft):\n",
    "    total=0\n",
    "    cfm=defaultdict(dict)\n",
    "\n",
    "    for line in lines:\n",
    "        t=0\n",
    "        if len(line.split(\" \"))<=1:\n",
    "            continue\n",
    "        tokens=line.split(\"\\t\")\n",
    "        tokens=tokens[0].split(\" \")\n",
    "        tokens.insert(0,\"START\")\n",
    "        tokens.append(\"END\")\n",
    "                \n",
    "        viterbi = [ ]\n",
    "        backpointer = [ ]\n",
    "        first_viterbi = { }\n",
    "        first_backpointer = { }\n",
    "        for tag in es:\n",
    "            if tag == \"START\":\n",
    "                continue\n",
    "            first_viterbi[tag] = transn(\"START\",tag,ts,fs)*emisn(tokens[0],tag,es,fs)\n",
    "            first_backpointer[tag] = \"START\"\n",
    "        viterbi.append(first_viterbi)\n",
    "        print (\"check1\")\n",
    "        backpointer.append(first_backpointer)\n",
    "        for i in range(1, len(tokens)-1):\n",
    "            this_viterbi = { }\n",
    "            this_backpointer = { }\n",
    "            prev_viterbi = viterbi[-1]\n",
    "            for tag in es:\n",
    "                if tag == \"START\":\n",
    "                    continue\n",
    "                best_previous = max(prev_viterbi.keys(), key = lambda prevtag:prev_viterbi[prevtag]*transn(prevtag,tag,es,fs)*emisn(tokens[i],tag,es,fs))\n",
    "                this_viterbi[tag] = prev_viterbi[best_previous]*transn(best_previous,tag,ts,fs)*emisn(tokens[i],tag,es,fs)\n",
    "                this_backpointer[ tag ] = best_previous\n",
    "            viterbi.append(this_viterbi)\n",
    "            backpointer.append(this_backpointer)\n",
    "        \n",
    "        prev_viterbi = viterbi[-1]\n",
    "        best_previous = max(prev_viterbi.keys(),key = lambda prevtag: prev_viterbi[prevtag]*transn(prevtag,\"END\",ts,fs))\n",
    "        prob_tagsequence = prev_viterbi[ best_previous ]*transn(best_previous,\"END\",ts,fs)\n",
    "        best_tagsequence = [ \"END\", best_previous ]\n",
    "        \n",
    "        backpointer.reverse()\n",
    "        current_best_tag = best_previous\n",
    "        for bp in backpointer:\n",
    "            best_tagsequence.append(bp[current_best_tag])\n",
    "            current_best_tag = bp[current_best_tag]\n",
    "        best_tagsequence.reverse()\n",
    "    \n",
    "        if best_tagsequence[-2]==\"neg\":\n",
    "            fw.write(str(total)+\",-1\"+\"\\n\")\n",
    "        elif best_tagsequence[-2]==\"pos\":\n",
    "            fw.write(str(total)+\",1\"+\"\\n\")\n",
    "        else:\n",
    "            fw.write(str(total)+\",0\"+\"\\n\")\n",
    "        total+=1\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viterbi(tagfreqs,tags,trans,freqs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
